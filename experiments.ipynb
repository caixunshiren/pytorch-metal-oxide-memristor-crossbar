{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1:\n",
    "# first, creating a set of N randomly generated (m, 1) vectors:\n",
    "import numpy as np\n",
    "m = 5\n",
    "N = 100\n",
    "vectors = [np.random.rand(*(m, 1)) for _ in range(N)] # uniform distribution between 0 and 1\n",
    "# print (vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 98, 1: 83, 2: 83, 3: 89, 4: 10, 5: 91, 6: 82, 7: 0, 8: 88, 9: 75, 10: 0, 11: 74, 12: 33, 13: 39, 14: 37, 15: 41, 16: 94, 17: 72, 18: 91, 19: 68, 20: 19, 21: 12, 22: 50, 23: 41, 24: 82, 25: 79, 26: 71, 27: 57, 28: 15, 29: 60, 30: 67, 31: 69, 32: 42, 33: 84, 34: 23, 35: 67, 36: 70, 37: 14, 38: 82, 39: 56, 40: 84, 41: 87, 42: 80, 43: 6, 44: 54, 45: 56, 46: 78, 47: 55, 48: 98, 49: 72, 50: 77, 51: 36, 52: 57, 53: 50, 54: 44, 55: 47, 56: 33, 57: 52, 58: 29, 59: 96, 60: 87, 61: 5, 62: 78, 63: 97, 64: 80, 65: 99, 66: 82, 67: 35, 68: 19, 69: 31, 70: 36, 71: 26, 72: 49, 73: 94, 74: 11, 75: 61, 76: 6, 77: 50, 78: 62, 79: 66, 80: 42, 81: 62, 82: 6, 83: 1, 84: 33, 85: 99, 86: 29, 87: 41, 88: 7, 89: 59, 90: 16, 91: 5, 92: 91, 93: 60, 94: 16, 95: 89, 96: 59, 97: 77, 98: 0, 99: 65}\n"
     ]
    }
   ],
   "source": [
    "# finding nearest neighbor of each vector using O(N^2) brute force approach:\n",
    "nearest_neighbors = {} # the keys will be the indices of the vectors from 0 to N-1, and the corresponding values will be the indices of its nearest neighbor\n",
    "for i in range(len(vectors)):\n",
    "    nearest_dist = float('inf')\n",
    "    nearest_neighbors[i] = None\n",
    "    for j in range(len(vectors)):\n",
    "        if j != i:\n",
    "            dist = np.linalg.norm(vectors[i] - vectors[j])\n",
    "            if dist < nearest_dist:\n",
    "                nearest_dist = dist\n",
    "                nearest_neighbors[i] = j\n",
    "print (nearest_neighbors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahsan\\Desktop\\pytorch-metal-oxide-memristor-crossbar\\memristor\\crossbar\\model.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  self.fitted_w = torch.tensor([[self.memristors[i][j].g_linfit for j in range(ideal_w.shape[1])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "010\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "010\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "010\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "010\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "010\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "010\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "010\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "010\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "010\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "010\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "111\n",
      "111\n",
      "111\n",
      "011\n",
      "011\n",
      "011\n",
      "{0: 98, 1: 83, 2: 83, 3: 88, 4: 10, 5: 91, 6: 82, 7: 0, 8: 88, 9: 92, 10: 0, 11: 74, 12: 33, 13: 39, 14: 37, 15: 41, 16: 94, 17: 22, 18: 59, 19: 68, 20: 19, 21: 12, 22: 50, 23: 41, 24: 1, 25: 79, 26: 71, 27: 57, 28: 15, 29: 60, 30: 58, 31: 69, 32: 42, 33: 84, 34: 23, 35: 67, 36: 70, 37: 14, 38: 82, 39: 56, 40: 84, 41: 15, 42: 32, 43: 24, 44: 54, 45: 56, 46: 78, 47: 55, 48: 98, 49: 72, 50: 53, 51: 36, 52: 57, 53: 50, 54: 44, 55: 47, 56: 33, 57: 52, 58: 29, 59: 96, 60: 87, 61: 75, 62: 14, 63: 97, 64: 80, 65: 99, 66: 82, 67: 35, 68: 19, 69: 31, 70: 36, 71: 26, 72: 49, 73: 94, 74: 11, 75: 61, 76: 6, 77: 97, 78: 46, 79: 66, 80: 64, 81: 78, 82: 6, 83: 1, 84: 33, 85: 99, 86: 35, 87: 60, 88: 7, 89: 59, 90: 16, 91: 5, 92: 91, 93: 60, 94: 16, 95: 89, 96: 59, 97: 77, 98: 0, 99: 65}\n"
     ]
    }
   ],
   "source": [
    "# finding nearest neighbor of each vector using NaiveLSH:\n",
    "from memristor.engine.model import NaiveLSH\n",
    "from memristor.crossbar.model import LineResistanceCrossbar\n",
    "from memristor.devices import StaticMemristor\n",
    "naive_lsh = NaiveLSH(\n",
    "    hash_size=3, # adjustable hyperparameter\n",
    "    crossbar_class=LineResistanceCrossbar,\n",
    "    crossbar_params={'r_wl': 20, 'r_bl': 20, 'r_in':10, 'r_out':10, 'V_SOURCE_MODE':'|_|'},\n",
    "    memristor_model_class=StaticMemristor,\n",
    "    memristor_params={'frequency': 1e8, 'temperature': 273 + 40},\n",
    "    m=m,\n",
    "    r=1, # adjustable hyperparameter\n",
    ")\n",
    "reps = 5 # adjustable hyperparameter (repetitions of the hashing)\n",
    "all_bins = []\n",
    "for _ in range(reps):\n",
    "    bins = {}\n",
    "    for i in range(len(vectors)):\n",
    "        hash = naive_lsh.inference(vectors[i])\n",
    "        print (hash)\n",
    "        if hash not in bins.keys():\n",
    "            bins[hash] = [i]\n",
    "        else:\n",
    "            bins[hash].append(i)\n",
    "    for bin in list(bins.values()):\n",
    "        all_bins.append(bin)\n",
    "#      {010:[1,5,7], 111:[5,6,7]}\n",
    "\n",
    "# now at this point all_bins is a list like [[1,2], [1,3,5], ... ] where each element of all_bins is a bin containing indices of vectors that are likely\n",
    "# to be close to each other. so now to find the nearest neighbor for each vector, we simply iterate through and check only those vectors that share a bin\n",
    "# with it, so in this case for 1 we would check 2, 3, and 5, to find the nearest neighbor\n",
    "nearest_neighbors_approx = {}\n",
    "for i in range(len(vectors)):\n",
    "    nearest_dist = float('inf')\n",
    "    nearest_neighbors_approx[i] = None\n",
    "    for bin in all_bins:\n",
    "        if i in bin:\n",
    "            for j in bin:\n",
    "                if j != i:\n",
    "                    dist = np.linalg.norm(vectors[i] - vectors[j])\n",
    "                    if dist < nearest_dist:\n",
    "                        nearest_dist = dist \n",
    "                        nearest_neighbors_approx[i] = j\n",
    "print (nearest_neighbors_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 98, 1: 83, 2: 83, 3: 89, 4: 10, 5: 91, 6: 82, 7: 0, 8: 88, 9: 75, 10: 0, 11: 74, 12: 33, 13: 39, 14: 37, 15: 41, 16: 94, 17: 72, 18: 91, 19: 68, 20: 19, 21: 12, 22: 50, 23: 41, 24: 82, 25: 79, 26: 71, 27: 57, 28: 15, 29: 60, 30: 67, 31: 69, 32: 42, 33: 84, 34: 23, 35: 67, 36: 70, 37: 14, 38: 82, 39: 56, 40: 84, 41: 87, 42: 80, 43: 6, 44: 54, 45: 56, 46: 78, 47: 55, 48: 98, 49: 72, 50: 77, 51: 36, 52: 57, 53: 50, 54: 44, 55: 47, 56: 33, 57: 52, 58: 29, 59: 96, 60: 87, 61: 5, 62: 78, 63: 97, 64: 80, 65: 99, 66: 82, 67: 35, 68: 19, 69: 31, 70: 36, 71: 26, 72: 49, 73: 94, 74: 11, 75: 61, 76: 6, 77: 50, 78: 62, 79: 66, 80: 42, 81: 62, 82: 6, 83: 1, 84: 33, 85: 99, 86: 29, 87: 41, 88: 7, 89: 59, 90: 16, 91: 5, 92: 91, 93: 60, 94: 16, 95: 89, 96: 59, 97: 77, 98: 0, 99: 65}\n",
      "{0: 98, 1: 83, 2: 83, 3: 88, 4: 10, 5: 91, 6: 82, 7: 0, 8: 88, 9: 92, 10: 0, 11: 74, 12: 33, 13: 39, 14: 37, 15: 41, 16: 94, 17: 22, 18: 59, 19: 68, 20: 19, 21: 12, 22: 50, 23: 41, 24: 1, 25: 79, 26: 71, 27: 57, 28: 15, 29: 60, 30: 58, 31: 69, 32: 42, 33: 84, 34: 23, 35: 67, 36: 70, 37: 14, 38: 82, 39: 56, 40: 84, 41: 15, 42: 32, 43: 24, 44: 54, 45: 56, 46: 78, 47: 55, 48: 98, 49: 72, 50: 53, 51: 36, 52: 57, 53: 50, 54: 44, 55: 47, 56: 33, 57: 52, 58: 29, 59: 96, 60: 87, 61: 75, 62: 14, 63: 97, 64: 80, 65: 99, 66: 82, 67: 35, 68: 19, 69: 31, 70: 36, 71: 26, 72: 49, 73: 94, 74: 11, 75: 61, 76: 6, 77: 97, 78: 46, 79: 66, 80: 64, 81: 78, 82: 6, 83: 1, 84: 33, 85: 99, 86: 35, 87: 60, 88: 7, 89: 59, 90: 16, 91: 5, 92: 91, 93: 60, 94: 16, 95: 89, 96: 59, 97: 77, 98: 0, 99: 65}\n"
     ]
    }
   ],
   "source": [
    "print (nearest_neighbors)\n",
    "print (nearest_neighbors_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors == nearest_neighbors_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "[[0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 19, 20, 21, 25, 26, 29, 30, 33, 37, 38, 39, 40, 44, 45, 48, 49, 54, 56, 58, 60, 62, 63, 64, 65, 66, 68, 71, 72, 76, 77, 79, 80, 82, 84, 85, 87, 88, 91, 92, 93, 97, 98, 99], [1, 2, 11, 15, 16, 17, 18, 22, 23, 24, 27, 28, 31, 32, 34, 35, 36, 41, 42, 43, 46, 47, 50, 51, 52, 53, 55, 57, 59, 67, 69, 70, 73, 74, 78, 81, 83, 86, 89, 90, 94, 95, 96], [61, 75], [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 19, 20, 21, 25, 26, 29, 30, 33, 37, 38, 39, 40, 44, 45, 48, 49, 54, 56, 58, 60, 62, 63, 64, 65, 66, 68, 71, 72, 76, 77, 79, 80, 82, 84, 85, 87, 88, 91, 92, 93, 97, 98, 99], [1, 2, 11, 15, 16, 17, 18, 22, 23, 24, 27, 28, 31, 32, 34, 35, 36, 41, 42, 43, 46, 47, 50, 51, 52, 53, 55, 57, 59, 67, 69, 70, 73, 74, 78, 81, 83, 86, 89, 90, 94, 95, 96], [61, 75], [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 19, 20, 21, 25, 26, 29, 30, 33, 37, 38, 39, 40, 44, 45, 48, 49, 54, 56, 58, 60, 62, 63, 64, 65, 66, 68, 71, 72, 76, 77, 79, 80, 82, 84, 85, 87, 88, 91, 92, 93, 97, 98, 99], [1, 2, 11, 15, 16, 17, 18, 22, 23, 24, 27, 28, 31, 32, 34, 35, 36, 41, 42, 43, 46, 47, 50, 51, 52, 53, 55, 57, 59, 67, 69, 70, 73, 74, 78, 81, 83, 86, 89, 90, 94, 95, 96], [61, 75], [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 19, 20, 21, 25, 26, 29, 30, 33, 37, 38, 39, 40, 44, 45, 48, 49, 54, 56, 58, 60, 62, 63, 64, 65, 66, 68, 71, 72, 76, 77, 79, 80, 82, 84, 85, 87, 88, 91, 92, 93, 97, 98, 99], [1, 2, 11, 15, 16, 17, 18, 22, 23, 24, 27, 28, 31, 32, 34, 35, 36, 41, 42, 43, 46, 47, 50, 51, 52, 53, 55, 57, 59, 67, 69, 70, 73, 74, 78, 81, 83, 86, 89, 90, 94, 95, 96], [61, 75], [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 19, 20, 21, 25, 26, 29, 30, 33, 37, 38, 39, 40, 44, 45, 48, 49, 54, 56, 58, 60, 62, 63, 64, 65, 66, 68, 71, 72, 76, 77, 79, 80, 82, 84, 85, 87, 88, 91, 92, 93, 97, 98, 99], [1, 2, 11, 15, 16, 17, 18, 22, 23, 24, 27, 28, 31, 32, 34, 35, 36, 41, 42, 43, 46, 47, 50, 51, 52, 53, 55, 57, 59, 67, 69, 70, 73, 74, 78, 81, 83, 86, 89, 90, 94, 95, 96], [61, 75]]\n",
      "[55, 43, 2, 55, 43, 2, 55, 43, 2, 55, 43, 2, 55, 43, 2]\n"
     ]
    }
   ],
   "source": [
    "print (len(all_bins))\n",
    "print (all_bins)\n",
    "print ([len(bin) for bin in all_bins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when experimenting with like a bigger dataset and stuff come up with  a metric to compare these 2 dicts\n",
    "# also compare the runtime complexities, cuz its possible that its working so well because of sth wrong in the implementation whiich results in the runtime\n",
    "# just being the same as the brute force method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthings to check: \\n- sizes of the bins, should not be big because otherwise there would be no runtime improvement -> get metrics for reduction of search space/runtime or space complexity\\n- varying the parameters like N, m, hash size, etc. (try bigger/more data)\\n- using lineres_memristive_vmm not naive_memristive_vmm\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "things to check: \n",
    "- sizes of the bins, should not be big because otherwise there would be no runtime improvement -> get metrics for reduction of search space/runtime or space complexity\n",
    "- varying the parameters like N, m, hash size, etc. (try bigger/more data)\n",
    "- using lineres_memristive_vmm not naive_memristive_vmm\n",
    "- experiment with varying non-idealities\n",
    "- experiment 2, create visualizations\n",
    "- write section 4 of the paper    (rn highest priority is finalizing the experiment and section 4 of the paper)\n",
    "- is the change made in StaticMemristor fine?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "messi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
